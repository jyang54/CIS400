{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        analysis                                         clean_text\n",
       "0      positive  Vaccine appointments available Rite Aid Pharma...\n",
       "1       neutral  If received Covid 19 Vaccine Covid Status Wear...\n",
       "2      positive  Much harder celebrate today extremely grateful...\n",
       "3       neutral  WHO approves Moderna COVID 19 vaccine emergenc...\n",
       "4      negative  LIST Here 8 pharmacies Brampton Mississauga of...\n",
       "...         ...                                                ...\n",
       "69677  positive  I get shots thankfully I able get Pfizer vacci...\n",
       "69678   neutral        Ruby Sheppard hospitalized COVID 19 vaccine\n",
       "69679   neutral  NACI recommends J amp J shot 30 age group pref...\n",
       "69680  negative  The Pfizer Phase III trial enrolled tens thous...\n",
       "69681  positive  Went Indianapolis Motor Speedway Tuesday talk ...\n",
       "\n",
       "[69682 rows x 2 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = pd.read_csv('t_data.csv', usecols = ['analysis','clean_text'])\n",
    "dfs.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction - setting max features to 10000\n",
    "X = dfs['clean_text'].values.astype('U')\n",
    "tfidf = TfidfVectorizer(max_features = 10000)\n",
    "X = tfidf.fit_transform(X)\n",
    "y = dfs['analysis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69682, 10000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train set : test set = 8:2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Support Vector Machine\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.76      0.81      2031\n",
      "     neutral       0.90      0.96      0.93      4545\n",
      "    positive       0.94      0.93      0.93      7361\n",
      "\n",
      "    accuracy                           0.91     13937\n",
      "   macro avg       0.90      0.88      0.89     13937\n",
      "weighted avg       0.91      0.91      0.91     13937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification & result\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.34      0.48      2031\n",
      "     neutral       0.84      0.62      0.71      4545\n",
      "    positive       0.71      0.94      0.81      7361\n",
      "\n",
      "    accuracy                           0.75     13937\n",
      "   macro avg       0.78      0.63      0.67     13937\n",
      "weighted avg       0.77      0.75      0.73     13937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification & result\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phabby/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.65      0.74      2031\n",
      "     neutral       0.86      0.95      0.90      4545\n",
      "    positive       0.92      0.92      0.92      7361\n",
      "\n",
      "    accuracy                           0.89     13937\n",
      "   macro avg       0.88      0.84      0.86     13937\n",
      "weighted avg       0.89      0.89      0.89     13937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification & result\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "clf = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.49      0.64      2031\n",
      "     neutral       0.84      0.91      0.87      4545\n",
      "    positive       0.86      0.93      0.89      7361\n",
      "\n",
      "    accuracy                           0.86     13937\n",
      "   macro avg       0.87      0.78      0.80     13937\n",
      "weighted avg       0.86      0.86      0.85     13937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification & result\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.49      0.64      2031\n",
      "     neutral       0.84      0.91      0.87      4545\n",
      "    positive       0.86      0.93      0.89      7361\n",
      "\n",
      "    accuracy                           0.86     13937\n",
      "   macro avg       0.87      0.78      0.80     13937\n",
      "weighted avg       0.86      0.86      0.85     13937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification & result\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
